  Алексей, к чему так близко воспринимать альтернативные мнения, читать между строчек и терять человеческое лицо? Реальные ситуации гораздо многообразнее чем жесткий набор правил и догм.

Я полагал, что публикация на хабре является приглашением к дискуссии, а не площадкой корпоративного тщеславия. Формулировку про распределенную отказоустойчивую систему Вы уже сами додумали.

Тем не менее, чтобы не осталось непонимания.
1. Как я неоднократно приписывал, особенности конкретного решения зависят от исходной бизнес-задачи, архитектуры и используемых инструментов. В разных случаях возможны разные режимы функционирования.
2. В упомянутом мной кейсе про "90%" мы грамотно проанализировали бизнес задачу и допустимые режимы функционирования подсистемы, создали мат.модель, определили допустимые параметры и разработали подсистему конкретно под задачу конвертации CDR. Было это еще а ~2006-7 годах. В итоге, вместо  закупки HP Superdome обошлись двумя SunFire 210 (или 240, точно уже не помню, давно было) в режиме Hot-Standy. Моментальный профит в разнице цен на железо! Ну и аптайм нашей подсистемы порядка 5 лет всех полностью устроил. Никого при этом нагрузка системы на 90% не беспокоила, все было промоделировано и рассчитано.
3. Например, в классе вычислительных задач, недозагрузка отдельного сервера в распределенной отказоустойчивой системы является злом. Есть поток данных, есть распределенные вычислители. При больших N вместо N серверов, работающих на 20% правильно использовать N/4 работающих на 100% + в резерве +1(+2, +3, +N/10) дополнительных вычислителей, готовых принять поток данных на обработку по мере необходимости. А еще и GPU при этом неплохо бы загрузить, чего зря стоять. Умный балансировщик гоняет задания исходя из состояния вычислителей, а не карусельным принципом. Но это уже вопросы архитектуры. Износ оборудования, обогрев воздуха, затраты на электричество -- на круг получается совсем не копейка.
4. Хорошо, когда маржа в 100-300% позволяет покрывать любую неэффективность. Однако, переход к марже в 12-15% заставляет владельцев резко задуматься об оптимизации. Туалетную бумагу начинают под расписку выдавать. Мы все видим, что сейчас происходит на рынке и долгосрочные прогнозы не предсказывают возврата к прошлой модели потребления.
5. "ИМХО" не подразумевает воинственной риторики. В переводе это означает in my humble opinion «по моему скромному мнению». Скромному человеку всегда интересно посмотреть опыт коллег, решающих масштабные задачи. Я не просто так упомянул NetFlix, Twitter, Facebook. Они вряд ли меньше ОК по своим масштабам, но делают очень интересные и красивые вещи, более того, делятся этим в открытую.

- [The Netflix Tech Blog](http://techblog.netflix.com/), в частности, по мониторингу взглянуть сюда:
	- [Evolution of Open Source at Netflix](http://techblog.netflix.com/2015/10/evolution-of-open-source-at-netflix.html)
	- [Vizceral Open Source](http://techblog.netflix.com/2016/08/vizceral-open-source.html)
- [Facebook Engineering Blog](https://code.facebook.com/posts/)
- [The Twitter Engineering Blog](https://blog.twitter.com/engineering)

==========================================
 Всем, кто интересуется вопросами производительности таких масштабных систем я бы посоветовал, кроме классической математики, почитать блог и книги Brendann Gregg. Труд, заслуживающий внимания и уважения:
- [Brendan D. Gregg blog](http://www.brendangregg.com/index.html)
- Книга [Systems Performance: Enterprise and the Cloud](https://www.amazon.com/gp/product/0133390098)
- Книга [Solaris Performance and Tools: DTrace and MDB Techniques for Solaris 10 and OpenSolaris](https://www.amazon.com/gp/product/0131568191)
- Книга [DTrace: Dynamic Tracing in Oracle Solaris, Mac OS X and FreeBSD](https://www.amazon.com/gp/product/0132091518)

А еще можно почитать и поиспользовать:
- Сайт [Performance Dynamics Company](http://www.perfdynamics.com/)
- Книга [Guerrilla Capacity Planning: A Tactical Approach to Planning for Highly Scalable Applications and Services](https://www.amazon.com/Guerrilla-Capacity-Planning-Tactical-Applications/dp/3540261389)